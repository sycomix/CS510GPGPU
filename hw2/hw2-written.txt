Henry Cooney
Instructions / Writeup for HW2:

INSTRUCTIONS:
	
	Part A (Crossover Point) is in the CrossoverPoint directory. Part B
	(Game of Life) is in the GameOfLife directory.

	To compile either program: just use the included makefile.
	
	To run Crossover Point: ./vector_addition_timed
	To run Game of Life: ./gol


PART A:

     Last week, I timed the results of vector_addition.cu, so I didn't 
     need to make many changes to find the crossover point. On the linux 
     lab machines, GPU performance begins to overtake CPU performance
     at a vector length of around 2-3 million. Below is a table of
     my results: 

     
     | Vector Length | CPU Time (s) | GPU Time (s) | Ratio (CPU time / GPU time) |
     | 100           | 0.000001     | 0.000642     | 0.001558                    |
     | 1000          | 0.000004     | 0.000621     | 0.006441                    |
     | 10000         | 0.000037     | 0.000633     | 0.058452                    |
     | 100000        | 0.000338     | 0.001078     | 0.313544                    |
     | 1000000       | 0.003059     | 0.003636     | 0.841309                    |
     | 10000000      | 0.027678     | 0.022259     | 1.243452                    |

     
     Clearly, a fast GPU is not a worthy investment if you only plan to use
     it for vector addition. It's not surprising that the GPU performs so 
     badly, since the entire vector must be copied to the GPU and back
     in order to do fairly short computation. Additionally, threads don't 
     share any data in this kernel, so speed couldn't be optimized through use
     of shared memory.

PART B:

     I was able to implement Conway's Game of Life on the GPU. My
     program does the following:
     	     
       - First, runs Conway's on the CPU and GPU, and tests whether
	     results agree
       - Then, starts displaying Conway's on a continuous loop through
	     an X window.

     I think my kernel is pretty efficient. I took the following steps to 
     achieve good performance:

        - Implemented tiling. Each thread loads 1 item into shared memory,
	but reads 9 items. So, global memory accesses are cut down by a	
	factor of 9.
	- Uses the maximum allowable tile size for the GTX645 (32x32). This
	is slightly more efficient, since it results in less overlap between
	tiles.
	- Memory remains on the GPU for multiple timesteps. If you request
	a kernel for 10 timesteps, buffers will remain in place on the GPU,
	and are only copied to/from main memory once. Furthermore, buffers
	are swapped each timestep, so there's no need to copy the results 
	into the initial array between each kernel call. 

    Unfortunately, the program is NOT efficient when used with X window
    graphics. In order to render each frame, data must be copied back to main
    memory. Thus, while my code is capable of keeping memory on the GPU between
    timesteps, it can't do this if you want to actually display each frame.
    It would be possible to display data directly from the GPU using OpenGL,
    by binding the array to an OpenGL texture. This might require substantially
    reworking the code, to output the Game of Life board in an OpenGL texture
    format.


  
